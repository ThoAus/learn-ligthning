
  | Name     | Type               | Params
------------------------------------------------
0 | fc1      | Linear             | 78.5 K
1 | fc2      | Linear             | 5.0 K
2 | fc3      | Linear             | 1.3 K
3 | fc4      | Linear             | 260
4 | dropout  | Dropout            | 0
5 | loss_fn  | CrossEntropyLoss   | 0
6 | accuracy | MulticlassAccuracy | 0
------------------------------------------------
85.1 K    Trainable params
0         Non-trainable params
85.1 K    Total params
0.340     Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=50` reached.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
c:\Users\thoma\anaconda3\Lib\site-packages\lightning\pytorch\loggers\wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
c:\Users\thoma\anaconda3\Lib\site-packages\lightning\pytorch\callbacks\model_checkpoint.py:653: Checkpoint directory .\MNIST\qu30nvkq\checkpoints exists and is not empty.

  | Name     | Type               | Params
------------------------------------------------
0 | fc1      | Linear             | 62.8 K
1 | fc2      | Linear             | 3.2 K
2 | fc3      | Linear             | 820
3 | fc4      | Linear             | 210
4 | dropout  | Dropout            | 0
5 | loss_fn  | CrossEntropyLoss   | 0
6 | accuracy | MulticlassAccuracy | 0
------------------------------------------------
67.1 K    Trainable params
0         Non-trainable params
67.1 K    Total params
0.268     Total estimated model params size (MB)
c:\Users\thoma\anaconda3\Lib\site-packages\lightning\pytorch\trainer\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...
